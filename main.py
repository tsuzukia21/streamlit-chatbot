import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
from google.ai.generativelanguage_v1beta.types import Tool as GenAITool
from st_txt_copybutton import txt_copy
import math
from typing import Tuple, Union, List, Dict, Any, Optional
import base64
from st_chat_input_multimodal import multimodal_chat_input
import database as db
from langchain_core.messages import HumanMessage

st.set_page_config(layout="wide", page_title="streamlit chatbot",page_icon=":material/chat:")

# ãƒ¢ãƒ‡ãƒ«è¨­å®šã®ä¸€å…ƒç®¡ç†
MODEL_CONFIG = {
    "claude-sonnet-4.5": {
        "provider": "anthropic",
        "display_name": "Claude Sonnet 4.5",
        "index": 0,
        "llm_factory": lambda temp: ChatAnthropic(
            temperature=1.0,
            model_name="claude-sonnet-4-5-20250929",
            max_tokens=16384,
            timeout=120,
            max_retries=3,
            thinking={"type": "enabled","budget_tokens": 8192}
        )
    },
    "gemini-2.5-pro": {
        "provider": "google",
        "display_name": "Gemini 2.5 Pro",
        "index": 1,
        "llm_factory": lambda temp: ChatGoogleGenerativeAI(
            model="gemini-2.5-pro",
            temperature=1.0,
            thinking_budget=16000,
            include_thoughts=True
        )
    },
    "gpt-5": {
        "provider": "openai",
        "display_name": "GPT 5",
        "index": 2,
        "llm_factory": lambda temp: ChatOpenAI(
            model="gpt-5-chat-latest",
            temperature=1.0,
        )
    }
}

def get_user_id() -> str:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’å–å¾—
    """
    # ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®IDã‚’å„ªå…ˆ
    try:
        if st.user.is_logged_in:
            # Googleãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã¯subãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½¿ç”¨
            user_id = getattr(st.user, 'sub', None)
            if user_id:
                return user_id
    except Exception:
        pass
    
    # æ—¢å­˜ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼ˆäº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼‰
    try:
        cookies = st.context.cookies
        user_id = cookies.get("ajs_user_id") or cookies.get("ajs_anonymous_id")
        if user_id:
            return user_id
    except Exception:
        pass
    
    # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®ID
    if "fallback_user_id" not in st.session_state:
        import uuid
        st.session_state.fallback_user_id = f"user_{uuid.uuid4().hex[:16]}"
    return st.session_state.fallback_user_id

def initialize_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ã‚’ä¸€å…ƒç®¡ç†"""
    defaults = {
        "done": True,
        "save": False,
        "stop": False,
        "edit_states": {},
        "total_tokens": 0,
        "system_prompt": "ã‚ãªãŸã¯å„ªç§€ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
        "temperature": 1.0,
        "error_message": "",
        "model_index": 0,
        "chat_history": [],
        "model": "claude-sonnet-4.5",
        "reasoning": "",  # æ¨è«–éç¨‹ã®ä¿å­˜
        "current_conversation_id": None,  # ç¾åœ¨ã®ä¼šè©±ID
        "user_id": None,  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã®å–å¾—
    if st.session_state.user_id is None:
        st.session_state.user_id = get_user_id()
    
    # LLMåˆæœŸåŒ–ï¼ˆmodelãŒè¨­å®šã•ã‚ŒãŸå¾Œï¼‰
    if "llm" not in st.session_state:
        model_name = st.session_state.model
        config = MODEL_CONFIG[model_name]
        st.session_state.llm = config["llm_factory"]

def get_current_provider() -> str:
    """ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ã‚’å–å¾—"""
    model = st.session_state.get("model", "claude-sonnet-4.5")
    return MODEL_CONFIG.get(model, MODEL_CONFIG["claude-sonnet-4.5"])["provider"]

def copy_button(text: str, key_suffix: Union[int, str]) -> None:
    copy_button = txt_copy(label="copy", text_to_copy=text.replace("\\n", "\n"), key=f"text_clipboard_chat_{key_suffix}")
    if copy_button:
        st.toast("Copied!")

def check_token() -> bool:
    token_limit = 50000
    message_limit = 30
    def limit_error(msg: str) -> bool:
        st.error(msg, icon="ğŸš¨")
        st.session_state.done = True
        st.session_state.save = False
        return False
    
    if st.session_state.total_tokens > token_limit:
        persent=min(100, math.floor(100 * st.session_state.total_tokens / token_limit))
        return limit_error(f'Error: Text volume is {persent}% of the limit.  \nPlease delete unnecessary parts or reset the conversation')
    if len(st.session_state.chat_history) > message_limit:
        return limit_error('Error: Conversation limit exceeded. Please reset the conversation')
    return True

def clear_chat():
    st.session_state.chat_history = []
    st.session_state.total_tokens = 0
    st.session_state.done = True
    st.session_state.error_message = ""
    st.session_state.edit_states = {}
    st.session_state.reasoning = ""  # æ¨è«–éç¨‹ã‚‚ã‚¯ãƒªã‚¢
    st.rerun()

def create_new_conversation() -> None:
    """æ–°ã—ã„ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ï¼ˆDBã«ã¯æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡æ™‚ã«ä½œæˆï¼‰"""
    st.session_state.current_conversation_id = None
    st.session_state.chat_history = []
    st.session_state.reasoning = ""
    st.session_state.total_tokens = 0
    st.session_state.error_message = ""
    st.session_state.edit_states = {}
    st.rerun()

def load_conversation(conversation_id: str) -> None:
    """æ—¢å­˜ã®ä¼šè©±ã‚’èª­ã¿è¾¼ã‚€"""
    # ä¼šè©±ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    conv = db.get_conversation(conversation_id)
    if not conv or conv["is_deleted"]:
        st.error("ä¼šè©±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿
    messages = db.get_messages(conversation_id)
    
    st.session_state.current_conversation_id = conversation_id
    st.session_state.chat_history = messages
    st.session_state.reasoning = db.get_last_reasoning(conversation_id)
    st.session_state.total_tokens = db.get_conversation_tokens(conversation_id)
    st.session_state.error_message = ""
    st.session_state.edit_states = {}
    st.rerun()

def delete_current_conversation() -> None:
    """ç¾åœ¨ã®ä¼šè©±ã‚’å‰Šé™¤ï¼ˆè«–ç†å‰Šé™¤ï¼‰"""
    if st.session_state.current_conversation_id:
        db.delete_conversation(st.session_state.current_conversation_id)
        st.session_state.current_conversation_id = None
        st.session_state.chat_history = []
        st.session_state.reasoning = ""
        st.rerun()

def generate_title_from_message(message: str) -> str:
    """æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ä¼šè©±ã‚¿ã‚¤ãƒˆãƒ«ã‚’LLMã§ç”Ÿæˆ"""
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
    text_content = ""
    if isinstance(message, list):
        # ç”»åƒä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆã€ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã‚’æŠ½å‡º
        for item in message:
            if isinstance(item, dict) and item.get("type") == "text":
                text_content = item["text"]
                break
        if not text_content:
            return "ç”»åƒä»˜ãä¼šè©±"
    else:
        text_content = message
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ç°¡æ˜“ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆé–¢æ•°
    def fallback_title(text: str) -> str:
        if len(text) > 15:
            return text[:15] + "..."
        return text
    
    # LLMã§ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆã‚’è©¦ã¿ã‚‹
    try:
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            temperature=0.7,
            thinking_budget=0,
        )
        
        prompt = f"""ä»¥ä¸‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã—ã¦ã€15æ–‡å­—ä»¥å†…ã®ç°¡æ½”ãªä¼šè©±ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ã‚’å‡ºåŠ›ã—ã€å¥èª­ç‚¹ã‚„è¨˜å·ã¯ä¸è¦ã§ã™ã€‚

ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {text_content[:200]}

ã‚¿ã‚¤ãƒˆãƒ«:"""
        
        response = llm.invoke([HumanMessage(content=prompt)])
        title = response.content.strip()
        
        # 15æ–‡å­—ã‚’è¶…ãˆã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
        if len(title) > 15:
            title = title[:15] + "..."
        
        # ç©ºã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not title:
            return fallback_title(text_content)
        
        return title
        
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å¾“æ¥ã®æ–¹å¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return fallback_title(text_content)

def update_system_prompt():
    st.session_state.system_prompt = st.session_state.new_system_prompt

def update_model():
    """ãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆæ™‚ã«LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°"""
    model_name = st.session_state.model
    config = MODEL_CONFIG.get(model_name)
    if config:
        st.session_state.llm = config["llm_factory"]
        st.session_state.model_index = config["index"]

def on_stop() -> None:
    """stopæŠ¼ä¸‹æ™‚ã«åœæ­¢ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹ã€‚streamlitã®ä»•æ§˜ä¸Šãƒ«ãƒ¼ãƒ—ä¸­æ–­å¾Œã®å‡¦ç†ã¯å®Ÿè¡Œã•ã‚Œãªã„ã®ã§stateã€chat_historyæ›´æ–°ã™ã‚‹ã€‚"""
    response = st.session_state.get("response", "")
    if response:
        st.session_state.chat_history.append(("assistant", response))
    st.session_state.stop = True
    st.session_state.done = True
    st.session_state.save = False

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–
initialize_session_state()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½
with st.sidebar:
    # ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã®ç¢ºèª
    if not st.user.is_logged_in:
        st.warning("âš ï¸ ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™")
        if st.button("ğŸ” Googleã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ãƒ­ã‚°ã‚¤ãƒ³", use_container_width=True, type="primary", key="login_button"):
            st.login()
        st.stop()  # ãƒ­ã‚°ã‚¤ãƒ³ã™ã‚‹ã¾ã§ã“ã“ã§åœæ­¢
    else:
        # ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±è¡¨ç¤º
        st.success(f"ğŸ‘¤ {st.user.name}")
        if st.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", use_container_width=True, key="logout_button"):
            st.logout()
    
    st.divider()

with st.sidebar.container():
    st.markdown(":material/settings: ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    model_options = list(MODEL_CONFIG.keys())
    st.selectbox("model",
                 options=model_options,
                 format_func=lambda x: MODEL_CONFIG[x]["display_name"],
                 help="æ¨è«–ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã§ãã¾ã™ã€‚å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚",
                 index=st.session_state.model_index,
                 key="model",
                 on_change=update_model)
    st.text_area("system prompt",value=st.session_state.system_prompt,on_change=update_system_prompt,key="new_system_prompt",
                                 help="You can provide a prompt to the system. This is only effective at the first message transmission.")
    st.divider()
    st.markdown(":material/message: ä¼šè©±ç®¡ç†")
    
    # æ–°ã—ã„ä¼šè©±ãƒœã‚¿ãƒ³
    if st.button(":material/add: æ–°ã—ã„ä¼šè©±", use_container_width=True, type="primary"):
        create_new_conversation()
    
    # ä¼šè©±å‰Šé™¤ãƒœã‚¿ãƒ³ï¼ˆç¾åœ¨ã®ä¼šè©±ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤ºï¼‰
    if st.session_state.current_conversation_id:
        if st.button(":material/delete: ã“ã®ä¼šè©±ã‚’å‰Šé™¤", use_container_width=True):
            delete_current_conversation()
    
    conversations = db.get_conversations(st.session_state.user_id)
    
    if conversations:
        for conv in conversations:
            conv_id = conv["id"]
            title = conv["title"]
            updated_at = conv["updated_at"]
            
            # ç¾åœ¨ã®ä¼šè©±ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            is_current = conv_id == st.session_state.current_conversation_id
            button_type = "primary" if is_current else "secondary"
            
            # ä¼šè©±ãƒœã‚¿ãƒ³
            if st.button(
                f"{':material/push_pin: ' if is_current else ''}{title}",
                key=f"conv_{conv_id}",
                use_container_width=True,
                type=button_type,
                disabled=is_current
            ):
                load_conversation(conv_id)
    
def modify_message(messages, i):
    del messages[i:]
    return messages

def render_markdown(text: str) -> str:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’Markdownè¡¨ç¤ºç”¨ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã™ã‚‹ã€‚
    æ”¹è¡Œã‚’<br>ã«å¤‰æ›ã—ã€ç‰¹æ®Šæ–‡å­—ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã™ã‚‹ã€‚
    """
    return text.replace("\n", "<br>").replace("$", "\\$").replace("#", "\\#").replace("_", "\\_")

def render_uploaded_images(files: List[Dict]) -> None:
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤ºã™ã‚‹ã€‚
    """
    for file in files:
        if file.get("type", "").startswith("image/"):
            try:
                base64_data = file['data'].split(',')[1] if ',' in file['data'] else file['data']
                image_bytes = base64.b64decode(base64_data)
                st.image(image_bytes, caption=file['name'], width=200)
            except (ValueError, base64.binascii.Error, KeyError) as e:
                st.warning(f"ç”»åƒ '{file.get('name', 'unknown')}' ã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸ")
                st.write(f"ğŸ“ {file.get('name', 'unknown')}")

def build_prompt_template(image_urls: Optional[List[str]] = None) -> ChatPromptTemplate:
    """
    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
    image_urls ãŒ None ã¾ãŸã¯ç©ºã®å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã€ãã‚Œä»¥å¤–ã¯ç”»åƒä»˜ããƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¿”ã™ã€‚
    """
    if image_urls:
        # ç”»åƒä»˜ãã®å ´åˆ
        human_content: List[Dict[str, Any]] = [{"type": "text", "text": "{input}"}]
        for url in image_urls:
            human_content.append({
                "type": "image_url",
                "image_url": {"url": url}
            })
        return ChatPromptTemplate.from_messages(
            [
                ("system", st.session_state.system_prompt),
                MessagesPlaceholder(variable_name="conversation"),
                ("human", human_content),
            ]
        )
    else:
        # ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®å ´åˆ
        return ChatPromptTemplate.from_messages(
            [
                ("system", st.session_state.system_prompt),
                MessagesPlaceholder(variable_name="conversation"),
                ("human", "{input}"),
            ]
        )

def build_chain(prompt_template: ChatPromptTemplate):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚"""
    # LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
    llm_instance = st.session_state.llm(st.session_state.temperature)
    
    provider = get_current_provider()
    if provider == "openai":
        llm_instance = llm_instance.bind_tools([{"type": "web_search"}])
    elif provider == "google":
        llm_instance = llm_instance.bind_tools([GenAITool(google_search={})])
    elif provider == "anthropic":
        llm_instance = llm_instance.bind_tools([{"type": "web_search_20250305","name": "web_search", "max_uses": 5}])
    
    return (prompt_template | llm_instance).with_config({"run_name": "Chat", "tags": ["Chat"]})

def stream_response_anthropic(chain, input_text: str, conversation_history: List[Tuple[str, Union[str, List[Dict[str, Any]]]]], status_container, reasoning_placeholder, message_placeholder) -> Tuple[str, int]:
    """
    Anthropicç”¨ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ï¼ˆthinkingå¯¾å¿œï¼‰
    """
    st.session_state.response = ""
    st.session_state.reasoning = ""
    total_tokens: int = 0
    last_usage: Optional[Dict[str, Any]] = None
    
    for chunk in chain.stream({"input": input_text, "conversation": conversation_history}):
        if st.session_state.stop:
            break
        if isinstance(chunk.content, list) and len(chunk.content) > 0:
            content_item = chunk.content[0]
            if content_item.get("thinking"):
                status_container.update(label="AIã¯è€ƒãˆã¦ã„ã¾ã™...", state="running", expanded=True)
                st.session_state.reasoning += content_item["thinking"]
                reasoning_placeholder.markdown(st.session_state.reasoning.replace("\n", "  \n"), unsafe_allow_html=True)
            elif content_item.get("text"):
                status_container.update(label="å‡ºåŠ›ä¸­...", state="running", expanded=False)
                st.session_state.response += content_item["text"]
                message_placeholder.markdown(st.session_state.response.replace("\n", "  \n") + "â–Œ", unsafe_allow_html=True)
        try:
            if getattr(chunk, "usage_metadata", None):
                last_usage = chunk.usage_metadata
        except Exception:
            pass
    
    if last_usage:
        total_tokens = last_usage.get("total_tokens", 0)
    
    status_container.update(label="å®Œäº†", state="complete", expanded=False)
    message_placeholder.markdown(st.session_state.response.replace("\n", "  \n"))
    return st.session_state.response, total_tokens

def stream_response_google(chain, input_text: str, conversation_history: List[Tuple[str, Union[str, List[Dict[str, Any]]]]], status_container, reasoning_placeholder, message_placeholder) -> Tuple[str, int]:
    """
    Googleç”¨ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ï¼ˆthinkingå¯¾å¿œï¼‰
    """
    st.session_state.response = ""
    st.session_state.reasoning = ""
    total_tokens: int = 0
    
    for chunk in chain.stream({"input": input_text, "conversation": conversation_history}):
        if st.session_state.stop:
            break
        if isinstance(chunk.content, list) and len(chunk.content) > 0:
            content_item = chunk.content[0]
            if content_item.get("thinking"):
                status_container.update(label="AIã¯è€ƒãˆã¦ã„ã¾ã™...", state="running", expanded=True)
                st.session_state.reasoning += content_item["thinking"]
                reasoning_placeholder.markdown(st.session_state.reasoning.replace("\n", "  \n"), unsafe_allow_html=True)
        else:
            status_container.update(label="å‡ºåŠ›ä¸­...", state="running", expanded=False)
            st.session_state.response += chunk.content
            message_placeholder.markdown(st.session_state.response.replace("\n", "  \n") + "â–Œ", unsafe_allow_html=True)
        try:
            total_tokens += (chunk.usage_metadata or {}).get("total_tokens", 0)
        except Exception:
            pass
    
    status_container.update(label="å®Œäº†", state="complete", expanded=False)
    message_placeholder.markdown(st.session_state.response.replace("\n", "  \n"))
    return st.session_state.response, total_tokens

def stream_response_openai(chain, input_text: str, conversation_history: List[Tuple[str, Union[str, List[Dict[str, Any]]]]], status_container, message_placeholder) -> Tuple[str, int]:
    """
    OpenAIç”¨ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ï¼ˆéæ¨è«–ãƒ¢ãƒ‡ãƒ«ç”¨ï¼‰
    """
    st.session_state.response = ""
    st.session_state.reasoning = ""
    total_tokens: int = 0
    first_chunk_received = False
    
    # æœ€åˆã¯ã€ŒAIã¯è€ƒãˆã¦ã„ã¾ã™...ã€
    status_container.update(label="AIã¯è€ƒãˆã¦ã„ã¾ã™...", state="running", expanded=False)
    
    for chunk in chain.stream({"input": input_text, "conversation": conversation_history}):
        if st.session_state.stop:
            break
        
        # æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã‚’å—ã‘å–ã£ãŸã‚‰ã€Œå‡ºåŠ›ä¸­ã€ã«å¤‰æ›´
        if not first_chunk_received:
            first_chunk_received = True
            status_container.update(label="å‡ºåŠ›ä¸­...", state="running", expanded=False)
            
        if isinstance(chunk.content, list) and len(chunk.content) > 0:
            content_item = chunk.content[0]
            if content_item.get("text"):
                st.session_state.response += content_item["text"]
                message_placeholder.markdown(st.session_state.response.replace("\n", "  \n") + "â–Œ", unsafe_allow_html=True)
        
        # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®å–å¾—
        try:
            if getattr(chunk, "usage_metadata", None):
                usage = chunk.usage_metadata
                total_tokens = usage.get("total_tokens", 0)
        except Exception:
            pass
    
    # å®Œäº†
    status_container.update(label="å®Œäº†", state="complete", expanded=False)
    message_placeholder.markdown(st.session_state.response.replace("\n", "  \n"))
    return st.session_state.response, total_tokens

def run_chat_turn(
    prompt: str, 
    conversation_history: List[Tuple[str, Union[str, List[Dict[str, Any]]]]], 
    image_urls: Optional[List[str]] = None
) -> Tuple[str, int]:
    """
    ãƒãƒ£ãƒƒãƒˆã‚¿ãƒ¼ãƒ³ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œã‚’è¡Œã†å…±é€šé–¢æ•°ï¼ˆæ¨è«–å¯¾å¿œï¼‰
    
    Args:
        prompt: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        conversation_history: ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´
        image_urls: ç”»åƒã®data URI ãƒªã‚¹ãƒˆï¼ˆNoneã®å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼‰
    
    Returns:
        (response_text, total_tokens): ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°
    """
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ§‹ç¯‰
    prompt_template = build_prompt_template(image_urls)
    
    # ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰
    chain = build_chain(prompt_template)
    
    # ãƒ—ãƒ­ãƒã‚¤ãƒ€å–å¾—
    provider = get_current_provider()
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œã¨UIè¡¨ç¤º
    st.session_state.response = ""
    st.session_state.reasoning = ""
    
    with st.chat_message("assistant", avatar=":material/psychology:"):
        col1, col2 = st.columns([9, 1])
        with col2:
            _pressed = st.button("stop", on_click=on_stop)
            st.session_state.stop = _pressed
        with col1:
            if provider == "anthropic":
                with st.status(label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡", state="complete", expanded=False) as status_container:
                    reasoning_placeholder = st.empty()
                message_placeholder = st.empty()
                response, tokens = stream_response_anthropic(
                    chain=chain,
                    input_text=prompt,
                    conversation_history=conversation_history,
                    status_container=status_container,
                    reasoning_placeholder=reasoning_placeholder,
                    message_placeholder=message_placeholder,
                )
            elif provider == "google":
                with st.status(label="AIã¯è€ƒãˆã¦ã„ã¾ã™...", state="running", expanded=False) as status_container:
                    reasoning_placeholder = st.empty()
                message_placeholder = st.empty()
                response, tokens = stream_response_google(
                    chain=chain,
                    input_text=prompt,
                    conversation_history=conversation_history,
                    status_container=status_container,
                    reasoning_placeholder=reasoning_placeholder,
                    message_placeholder=message_placeholder,
                )
            elif provider == "openai":
                status_container = st.status(label="AIã¯è€ƒãˆã¦ã„ã¾ã™...", state="running", expanded=False)
                message_placeholder = st.empty()
                response, tokens = stream_response_openai(
                    chain=chain,
                    input_text=prompt,
                    conversation_history=conversation_history,
                    status_container=status_container,
                    message_placeholder=message_placeholder,
                )
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                message_placeholder = st.empty()
                message_placeholder.markdown("Unknown provider")
                response, tokens = "", 0
    
    return response, tokens

def render_human_message(message: Tuple[str, Union[str, List[Dict[str, Any]]]], index: int, edit: bool) -> None:
    """
    Render user-side messages.
    """
    
    with st.chat_message("human", avatar=":material/mood:"):
        col1, col2 = st.columns([9, 1])
        with col1:
            if isinstance(message[1], list):
                for item in message[1]:
                    if item["type"] == "text":
                        msg_content = item["text"]
                        st.markdown(render_markdown(msg_content), unsafe_allow_html=True)
                    elif item["type"] == "image_url":
                        st.image(item["image_url"]["url"])
            else:
                msg_content = message[1]
                st.markdown(render_markdown(msg_content), unsafe_allow_html=True)
                
        with col2:
            if edit:
                if st.button("edit", key=f"edit_{index}"):
                    st.session_state.edit_states[index] = True
            else:
                st.button("edit", key=f"dummy_{index}")
                
        if edit and st.session_state.edit_states.get(index):
            st.session_state.new_message = st.text_area("ç·¨é›†ã—ãŸã‚‰saveã—ã¦ãã ã•ã„ã€‚", value=msg_content, key=f"new_message_{index}")
            left, right = st.columns([9, 1])
            with right:
                if st.button("save", key=f"save_{index}", type="primary"):
                    st.session_state.edit_states[index] = False
                    
                    # DBã‹ã‚‰è©²å½“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä»¥é™ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤
                    if st.session_state.current_conversation_id:
                        db.delete_messages_from_index(
                            st.session_state.current_conversation_id, 
                            index
                        )
                    
                    # session_stateã‹ã‚‰ã‚‚å‰Šé™¤
                    modify_message(st.session_state.chat_history, index)
                    st.session_state.save = True

def render_assistant_message(message: Tuple[str, str], index: int, show_copy_button: bool) -> None:
    """
    Render assistant-side messages.
    """
    col1, col2 = st.columns([9, 1])
    with col1:
        with st.chat_message("assistant", avatar=":material/psychology:"):
            # æœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§æ¨è«–éç¨‹ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
            if index == len(st.session_state.chat_history) - 1 and hasattr(st.session_state, "reasoning") and st.session_state.reasoning:
                with st.expander("AIã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹", expanded=False):
                    st.markdown(st.session_state.reasoning.replace("\n", "  \n"), unsafe_allow_html=True)
            st.markdown(message[1].replace("\n","  \n"), unsafe_allow_html=True)
    with col2:
        if show_copy_button and index == len(st.session_state.chat_history) - 1:
            copy_button(message[1], index)

def show_chat_history(
    messages: List[Tuple[str, Union[str, List[Dict[str, Any]]]]],
    edit: bool,
    error_message: str,
    new_message: Optional[str] = None,
    show_copy_button: bool = True,
) -> None:
    """
    Display the entire chat history and render new messages as needed.
    """
    for i, message in enumerate(messages):
        if message[0] == "human":
            render_human_message(message, i, edit)
        elif message[0] == "assistant":
            render_assistant_message(message, i, show_copy_button)
    if new_message:
        with st.chat_message("user", avatar=":material/mood:"):
            st.markdown(render_markdown(new_message), unsafe_allow_html=True)
    if error_message:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚  \n{st.session_state.error_message}ã€‚  \nãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´ã™ã‚‹ã‹å†åº¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚",icon=":material/warning:")

st.title("Streamlit ChatBot")

user_input = multimodal_chat_input(
    placeholder="Send a message",
    enable_voice_input=True,
    voice_recognition_method="openai_whisper",
    voice_language="ja-JP",
    key="chat_input"
)

show_chat_history(messages=st.session_state.chat_history,edit=True, error_message=st.session_state.error_message, show_copy_button=True)

if user_input is not None:
    st.session_state.error_message = ""
    st.session_state.done = False
    ok = check_token()
    if ok:
        # ä¼šè©±ãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆ
        if not st.session_state.current_conversation_id:
            user_id = st.session_state.user_id
            title = "æ–°ã—ã„ä¼šè©±"  # æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§è‡ªå‹•æ›´æ–°ã•ã‚Œã‚‹
            conversation_id = db.create_conversation(user_id, title)
            st.session_state.current_conversation_id = conversation_id
        
        # Extract text from multimodal input
        input_text = user_input.get("text", "")
        input_files = user_input.get("files", [])
        
        # Use text content for LangChain input
        llm_input = input_text if input_text else "Image uploaded"
        
        # Display user message with images
        with st.chat_message("human", avatar=":material/mood:"):
            col1, col2 = st.columns([9, 1])
            with col1:
                if input_text:
                    st.markdown(render_markdown(input_text), unsafe_allow_html=True)
                
                # Display images
                render_uploaded_images(input_files)
        
        # Extract image URLs for prompt template
        image_urls: List[str] = []
        for file in input_files:
            if file.get("type", "").startswith("image/"):
                try:
                    base64_data = file['data'].split(',')[1] if ',' in file['data'] else file['data']
                    # Validate base64 data
                    base64.b64decode(base64_data)
                    image_urls.append(file["data"])
                except (ValueError, base64.binascii.Error) as e:
                    st.warning(f"ç”»åƒ '{file.get('name', 'unknown')}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        
        # Add human message to history
        if image_urls:
            human_payload: List[Dict[str, Any]] = []
            if input_text:
                human_payload.append({"type": "text", "text": input_text})
            for url in image_urls:
                human_payload.append({"type": "image_url", "image_url": {"url": url}})
            st.session_state.chat_history.append(("human", human_payload))
        else:
            st.session_state.chat_history.append(("human", input_text))
        
        # DBã«äººé–“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
        conversation_id = st.session_state.current_conversation_id
        human_content = human_payload if image_urls else input_text
        db.save_message_with_images(conversation_id, "human", human_content)
        
        # æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆã€ä¼šè©±ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ›´æ–°
        if len(st.session_state.chat_history) == 1:
            title = generate_title_from_message(human_content)
            db.update_conversation_title(conversation_id, title)
        
        # Execute chat turn
        response, tokens = run_chat_turn(
            prompt=llm_input,
            conversation_history=st.session_state.chat_history[:-1],
            image_urls=image_urls if image_urls else None
        )
        
        # ä¼šè©±ã®ç´¯ç©ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ›´æ–°
        db.update_conversation_tokens(conversation_id, tokens)
        st.session_state.total_tokens = db.get_conversation_tokens(conversation_id)
        
        st.session_state.chat_history.append(("assistant", response))
        
        # DBã«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
        db.save_message_with_images(
            conversation_id, 
            "assistant", 
            response, 
            reasoning=st.session_state.reasoning
        )
        
        # Reset state and rerun
        st.session_state.done = True
        st.session_state.stop = False
        st.rerun()

if st.session_state.save:
    st.session_state.error_message = ""
    st.session_state.done = False
    prompt = st.session_state.new_message
    show_chat_history(messages=st.session_state.chat_history, edit=False, error_message=st.session_state.error_message, new_message=prompt, show_copy_button=False)
    ok = check_token()
    if not ok:
        st.session_state.save = False
    else:
        # ä¼šè©±ãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆ
        if not st.session_state.current_conversation_id:
            user_id = st.session_state.user_id
            title = "æ–°ã—ã„ä¼šè©±"  # æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§è‡ªå‹•æ›´æ–°ã•ã‚Œã‚‹
            conversation_id = db.create_conversation(user_id, title)
            st.session_state.current_conversation_id = conversation_id
        
        # Add edited human message to history
        st.session_state.chat_history.append(("human", prompt))
        
        # DBã«äººé–“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
        conversation_id = st.session_state.current_conversation_id
        db.save_message_with_images(conversation_id, "human", prompt)
        
        # Execute chat turn (text only, no images for edited messages)
        response, tokens = run_chat_turn(
            prompt=prompt,
            conversation_history=st.session_state.chat_history[:-1],
            image_urls=None
        )
        
        # ä¼šè©±ã®ç´¯ç©ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ›´æ–°
        db.update_conversation_tokens(conversation_id, tokens)
        st.session_state.total_tokens = db.get_conversation_tokens(conversation_id)
        
        st.session_state.chat_history.append(("assistant", response))
        
        # DBã«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
        db.save_message_with_images(
            conversation_id, 
            "assistant", 
            response, 
            reasoning=st.session_state.reasoning
        )
        
        # Reset state and rerun
        st.session_state.done = True
        st.session_state.save = False
        st.session_state.stop = False
        st.rerun()

